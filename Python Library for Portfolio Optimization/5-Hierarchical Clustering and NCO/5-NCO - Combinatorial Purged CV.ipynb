{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# NCO - Combinatorial Purged CV\n\nThe previous tutorial introduced the\n:class:`~skfolio.optimization.NestedClustersOptimization`.\n\nIn this tutorial, we will perform hyperparameter search using `GridSearch` and\ndistribution analysis with `CombinatorialPurgedCV`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\nWe load the S&P 500 `dataset <datasets>` composed of the daily prices of 20\nassets from the S&P 500 Index composition starting from 2015-01-02 up to 2022-12-28:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from plotly.io import show\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nfrom skfolio import Population, RatioMeasure, RiskMeasure\nfrom skfolio.cluster import HierarchicalClustering, LinkageMethod\nfrom skfolio.datasets import load_sp500_dataset\nfrom skfolio.distance import KendallDistance, PearsonDistance\nfrom skfolio.model_selection import (\n    CombinatorialPurgedCV,\n    WalkForward,\n    cross_val_predict,\n)\nfrom skfolio.optimization import (\n    EqualWeighted,\n    MeanRisk,\n    NestedClustersOptimization,\n    RiskBudgeting,\n)\nfrom skfolio.preprocessing import prices_to_returns\n\nprices = load_sp500_dataset()\nprices = prices[\"2015\":]\n\nX = prices_to_returns(prices)\nX_train, X_test = train_test_split(X, test_size=0.5, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\nWe create two models: the NCO and the equal-weighted benchmark:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "benchmark = EqualWeighted()\n\nmodel_nco = NestedClustersOptimization(\n    inner_estimator=MeanRisk(), clustering_estimator=HierarchicalClustering()\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameter Tuning\nWe find the model parameters that maximizes the out-of-sample Sharpe ratio using\n`GridSearchCV` with `WalkForward` cross-validation on the training set.\nThe `WalkForward` are chosen to simulate a three months (60 business days) rolling\nportfolio fitted on the previous year (252 business days):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = WalkForward(train_size=252, test_size=60)\n\ngrid_search_hrp = GridSearchCV(\n    estimator=model_nco,\n    cv=cv,\n    n_jobs=-1,\n    param_grid={\n        \"inner_estimator__risk_measure\": [RiskMeasure.VARIANCE, RiskMeasure.CVAR],\n        \"outer_estimator\": [\n            EqualWeighted(),\n            RiskBudgeting(risk_measure=RiskMeasure.CVAR),\n        ],\n        \"clustering_estimator__linkage_method\": [\n            LinkageMethod.SINGLE,\n            LinkageMethod.WARD,\n        ],\n        \"distance_estimator\": [PearsonDistance(), KendallDistance()],\n    },\n)\ngrid_search_hrp.fit(X_train)\nmodel_nco = grid_search_hrp.best_estimator_\nprint(model_nco)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction\nWe evaluate the two models using the same `WalkForward` object on the test set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_bench = cross_val_predict(\n    benchmark,\n    X_test,\n    cv=cv,\n    portfolio_params=dict(name=\"Benchmark\"),\n)\n\npred_nco = cross_val_predict(\n    model_nco,\n    X_test,\n    cv=cv,\n    n_jobs=-1,\n    portfolio_params=dict(name=\"NCO\"),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each predicted object is a `MultiPeriodPortfolio`.\nFor improved analysis, we can add them to a `Population`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population = Population([pred_bench, pred_nco])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the rolling portfolios compositions:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population.plot_composition(display_sub_ptf_name=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the rolling portfolios cumulative returns on the test set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = population.plot_cumulative_returns()\nshow(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis\nThe NCO outperforms the Benchmark on the test set for the below measures:\nmaximization:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for ptf in population:\n    print(\"=\" * 25)\n    print(\" \" * 8 + ptf.name)\n    print(\"=\" * 25)\n    print(f\"Ann. Sharpe ratio : {ptf.annualized_sharpe_ratio:0.2f}\")\n    print(f\"CVaR ratio : {ptf.cvar_ratio:0.4f}\")\n    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combinatorial Purged Cross-Validation\nOnly using one testing path (the historical path) may not be enough for comparing both\nmodels. For a more robust analysis, we can use\n:class:`~skfolio.model_selection.CombinatorialPurgedCV` to create multiple testing\npaths from different training folds combinations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = CombinatorialPurgedCV(n_folds=9, n_test_folds=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We choose `n_folds` and `n_test_folds` to obtain more than 30 test paths and an average\ntraining size of approximately 252 days:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv.summary(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_nco = cross_val_predict(\n    model_nco,\n    X_test,\n    cv=cv,\n    n_jobs=-1,\n    portfolio_params=dict(tag=\"NCO\"),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The predicted object is a `Population` of `MultiPeriodPortfolio`. Each\n`MultiPeriodPortfolio` represents one testing path of a rolling portfolio.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribution\nWe plot the out-of-sample distribution of Sharpe Ratio for the NCO model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_nco.plot_distribution(measure_list=[RatioMeasure.ANNUALIZED_SHARPE_RATIO])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's print the average and standard-deviation of out-of-sample Sharpe Ratios:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"Average of Sharpe Ratio :\"\n    f\" {pred_nco.measures_mean(measure=RatioMeasure.ANNUALIZED_SHARPE_RATIO):0.2f}\"\n)\nprint(\n    \"Std of Sharpe Ratio :\"\n    f\" {pred_nco.measures_std(measure=RatioMeasure.ANNUALIZED_SHARPE_RATIO):0.2f}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare it with the benchmark:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_bench = benchmark.fit_predict(X_test)\nprint(pred_bench.annualized_sharpe_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nThis NCO model outperforms the Benchmark in terms of Sharpe Ratio on the historical\ntest set. However, the distribution analysis on the recombined (non-historical) test\nsets shows that it slightly underperforms the Benchmark in average.\n\nThis was a toy example to present the API. Further analysis using different\nestimators, datasets and CV parameters should be performed to determine if the\noutperformance on the historical test set is due to chance or if this NCO model is\nable to exploit time-dependencies information lost in `CombinatorialPurgedCV`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}