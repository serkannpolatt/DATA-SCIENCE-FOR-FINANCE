{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Nested Clusters Optimization\n\nThis tutorial introduces the :class:`~skfolio.optimization.NestedClustersOptimization`\noptimization.\n\nNested Clusters Optimization (NCO) is a portfolio optimization method developed by\nMarcos Lopez de Prado.\n\nIt uses a distance matrix to compute clusters using a clustering algorithm (\nHierarchical Tree Clustering, KMeans, etc..). For each cluster, the inner-cluster\nweights are computed by fitting the inner-estimator on each cluster using the whole\ntraining data. Then the outer-cluster weights are computed by training the\nouter-estimator using out-of-sample estimates of the inner-estimators with\ncross-validation. Finally, the final assets weights are the dot-product of the\ninner-weights and outer-weights.\n\n.. note ::\n\n    The original paper uses KMeans as the clustering algorithm, minimum Variance for\n    the inner-estimator and equal-weight for the outer-estimator. Here we generalize\n    it to all `sklearn` and `skfolio` clustering algorithm (Hierarchical Tree\n    Clustering, KMeans, etc.), all portfolio optimizations (Mean-Variance, HRP, etc.)\n    and risk measures (variance, CVaR, etc.).\n    To avoid data leakage at the outer-estimator, we use out-of-sample estimates to\n    fit the outer estimator.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\nWe load the S&P 500 `dataset <datasets>` composed of the daily prices of 20\nassets from the S&P 500 Index composition starting from 1990-01-02 up to 2022-12-28:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from plotly.io import show\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\n\nfrom skfolio import Population, RiskMeasure\nfrom skfolio.cluster import HierarchicalClustering, LinkageMethod\nfrom skfolio.datasets import load_sp500_dataset\nfrom skfolio.distance import KendallDistance\nfrom skfolio.optimization import (\n    EqualWeighted,\n    MeanRisk,\n    NestedClustersOptimization,\n    ObjectiveFunction,\n    RiskBudgeting,\n)\nfrom skfolio.preprocessing import prices_to_returns\n\nprices = load_sp500_dataset()\n\nX = prices_to_returns(prices)\nX_train, X_test = train_test_split(X, test_size=0.33, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\nWe create a NCO model that maximizes the Sharpe Ratio intra-cluster and uses a CVaR\nRisk Parity inter-cluster. By default, the inter-cluster optimization\nuses `KFolds` out-of-sample estimates of the inner-estimator to avoid data leakage.\nand the :class:`~skfolio.cluster.HierarchicalClustering` estimator\nto form the clusters:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inner_estimator = MeanRisk(\n    objective_function=ObjectiveFunction.MAXIMIZE_RATIO,\n    risk_measure=RiskMeasure.VARIANCE,\n)\nouter_estimator = RiskBudgeting(risk_measure=RiskMeasure.CVAR)\n\nmodel1 = NestedClustersOptimization(\n    inner_estimator=inner_estimator,\n    outer_estimator=outer_estimator,\n    n_jobs=-1,\n    portfolio_params=dict(name=\"NCO-1\"),\n)\nmodel1.fit(X_train)\nmodel1.weights_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dendrogram\nTo analyze the clusters structure, we can plot the dendrogram.\nThe blue lines represent distinct clusters composed of a single asset.\nThe remaining colors represent clusters of more than one asset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model1.clustering_estimator_.plot_dendrogram(heatmap=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The horizontal axis represent the assets. The links between clusters are represented\nas upside-down U-shaped lines. The height of the U indicates the distance between the\nclusters. For example, the link representing the cluster containing Assets HD and WMT\nhas a distance of 0.5 (called cophenetic distance).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When `heatmap` is set to True, the heatmap of the reordered distance matrix is\ndisplayed below the dendrogram and clusters are outlined with yellow squares:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model1.clustering_estimator_.plot_dendrogram()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linkage Methods\nThe hierarchical clustering can be greatly affected by the choice of the linkage\nmethod. In the :class:`~skfolio.cluster.HierarchicalClustering` estimator, the default\nlinkage method is set to the Ward variance minimization algorithm, which is more\nstable and has better properties than the single-linkage method which suffers from the\nchaining effect.\n\nTo show this effect, let's create a second model with the\nsingle-linkage method:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model2 = NestedClustersOptimization(\n    inner_estimator=inner_estimator,\n    outer_estimator=outer_estimator,\n    clustering_estimator=HierarchicalClustering(\n        linkage_method=LinkageMethod.SINGLE,\n    ),\n    n_jobs=-1,\n    portfolio_params=dict(name=\"NCO-2\"),\n)\nmodel2.fit(X_train)\nmodel2.clustering_estimator_.plot_dendrogram(heatmap=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distance Estimator\nThe distance metric used has also an important effect on the clustering.\nThe default is to use the distance of the pearson correlation matrix.\nThis can be changed using the `distance estimators <distance>`.\n\nFor example, let's create a third model with a distance computed from the absolute\nvalue of the Kendal correlation matrix:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model3 = NestedClustersOptimization(\n    inner_estimator=inner_estimator,\n    outer_estimator=outer_estimator,\n    distance_estimator=KendallDistance(absolute=True),\n    n_jobs=-1,\n    portfolio_params=dict(name=\"NCO-3\"),\n)\nmodel3.fit(X_train)\nmodel3.clustering_estimator_.plot_dendrogram(heatmap=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering Estimator\nThe above models used the default :class:`~skfolio.cluster.HierarchicalClustering`\nestimator. This can be replaced by any `sklearn` or `skfolio` clustering estimators.\n\nFor example, let's create a new model with `sklearn.cluster.KMeans`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model4 = NestedClustersOptimization(\n    inner_estimator=inner_estimator,\n    outer_estimator=outer_estimator,\n    clustering_estimator=KMeans(n_init=\"auto\"),\n    n_jobs=-1,\n    portfolio_params=dict(name=\"NCO-4\"),\n)\nmodel4.fit(X_train)\nmodel4.weights_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compare the NCO models, we use an equal weighted benchmark using\nthe :class:`~skfolio.optimization.EqualWeighted` estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bench = EqualWeighted()\nbench.fit(X_train)\nbench.weights_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction\nWe predict the models and the benchmark on the test set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population_test = Population([])\nfor model in [model1, model2, model3, model4, bench]:\n    population_test.append(model.predict(X_test))\n\npopulation_test.plot_cumulative_returns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Composition\nLet's plot each portfolio composition:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = population_test.plot_composition()\nshow(fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}