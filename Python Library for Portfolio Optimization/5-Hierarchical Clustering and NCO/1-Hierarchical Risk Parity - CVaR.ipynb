{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Hierarchical Risk Parity - CVaR\n\nThis tutorial introduces the :class:`~skfolio.optimization.HierarchicalRiskParity`\noptimization.\n\nHierarchical Risk Parity (HRP) is a portfolio optimization method developed by Marcos\nLopez de Prado.\n\nThis algorithm uses a distance matrix to compute hierarchical clusters using the\nHierarchical Tree Clustering algorithm. It then employs seriation to rearrange the\nassets in the dendrogram, minimizing the distance between leafs.\n\nThe final step is the recursive bisection where each cluster is split between two\nsub-clusters by starting with the topmost cluster and traversing in a top-down\nmanner. For each sub-cluster, we compute the total cluster risk of an inverse-risk\nallocation. A weighting factor is then computed from these two sub-cluster risks,\nwhich is used to update the cluster weight.\n\n.. note ::\n    The original paper uses the variance as the risk measure and the single-linkage\n    method for the Hierarchical Tree Clustering algorithm. Here we generalize it to\n    multiple risk measures and linkage methods.\n    The default linkage method is set to the Ward\n    variance minimization algorithm, which is more stable and has better properties\n    than the single-linkage method.\n\nIn this example, we will use the CVaR risk measure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\nWe load the S&P 500 `dataset <datasets>` composed of the daily prices of 20\nassets from the SPX Index composition and the Factors dataset composed of the daily\nprices of 5 ETF representing common factors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from plotly.io import show\nfrom sklearn.model_selection import train_test_split\n\nfrom skfolio import Population, RiskMeasure\nfrom skfolio.cluster import HierarchicalClustering, LinkageMethod\nfrom skfolio.datasets import load_factors_dataset, load_sp500_dataset\nfrom skfolio.distance import KendallDistance\nfrom skfolio.optimization import EqualWeighted, HierarchicalRiskParity\nfrom skfolio.preprocessing import prices_to_returns\nfrom skfolio.prior import FactorModel\n\nprices = load_sp500_dataset()\nfactor_prices = load_factors_dataset()\n\nprices = prices[\"2014\":]\nfactor_prices = factor_prices[\"2014\":]\n\nX, y = prices_to_returns(prices, factor_prices)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\nWe create the CVaR Hierarchical Risk Parity model and then fit it on the training set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model1 = HierarchicalRiskParity(\n    risk_measure=RiskMeasure.CVAR, portfolio_params=dict(name=\"HRP-CVaR-Ward-Pearson\")\n)\nmodel1.fit(X_train)\nmodel1.weights_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Risk Contribution\nLet's analyze the risk contribution of the model on the training set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ptf1 = model1.predict(X_train)\nptf1.plot_contribution(measure=RiskMeasure.CVAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dendrogram\nTo analyze the clusters structure, we plot the dendrogram.\nThe blue lines represent distinct clusters composed of a single asset.\nThe remaining colors represent clusters of more than one asset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model1.hierarchical_clustering_estimator_.plot_dendrogram(heatmap=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The horizontal axis represents the assets. The links between clusters are represented\nas upside-down U-shaped lines. The height of the U indicates the distance between the\nclusters. For example, the link representing the cluster containing assets HD and WMT\nhas a distance of 0.5 (called cophenetic distance).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When `heatmap` is set to True, the heatmap of the reordered distance matrix is\ndisplayed below the dendrogram and clusters are outlined with yellow squares:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = model1.hierarchical_clustering_estimator_.plot_dendrogram()\nshow(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linkage Methods\nThe clustering can be greatly affected by the choice of the linkage method.\nThe original HRP is based on the single-linkage (equivalent to the minimum spanning\ntree), which suffers from the chaining effect.\nIn the :class:`~skfolio.optimization.HierarchicalRiskParity` estimator, the default\nlinkage method is set to the Ward variance minimization algorithm, which is more\nstable and has better properties than the single-linkage method.\n\nHowever, since the HRP optimization doesn\u2019t utilize the full cluster structure but\nonly their orders, the allocation remains relatively stable regardless of the chosen\nlinkage method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To show this effect, let's create a second model with the single-linkage method:\nmodel2 = HierarchicalRiskParity(\n    risk_measure=RiskMeasure.CVAR,\n    hierarchical_clustering_estimator=HierarchicalClustering(\n        linkage_method=LinkageMethod.SINGLE,\n    ),\n    portfolio_params=dict(name=\"HRP-CVaR-Single-Pearson\"),\n)\nmodel2.fit(X_train)\n\nmodel2.hierarchical_clustering_estimator_.plot_dendrogram(heatmap=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the clustering has been greatly affected by the change of the linkage\nmethod. However, you will see bellow that the weights remain relatively stable for the\nreason explained earlier.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distance Estimator\nThe choice of distance metric has also an important effect on the clustering.\nThe default is to use the distance from the pearson correlation matrix.\nThis can be changed using the `distance estimators <distance>`.\n\nFor example, let's create a third model with a distance computed from the absolute\nvalue of the Kendal correlation matrix:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model3 = HierarchicalRiskParity(\n    risk_measure=RiskMeasure.CVAR,\n    distance_estimator=KendallDistance(absolute=True),\n    portfolio_params=dict(name=\"HRP-CVaR-Ward-Kendal\"),\n)\nmodel3.fit(X_train)\n\nmodel3.hierarchical_clustering_estimator_.plot_dendrogram(heatmap=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prior Estimator\nFinally, HRP like the other portfolio optimization, uses a\n`prior estimator <prior>` that fits a :class:`~skfolio.prior.PriorModel`\ncontaining the distribution estimate of asset returns. It represents the investor's\nprior beliefs about the model used to estimate such distribution.\nThe default is the :class:`~skfolio.prior.EmpiricalPrior` estimator.\n\nLet's create new model with the :class:`~skfolio.prior.FactorModel` estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model4 = HierarchicalRiskParity(\n    risk_measure=RiskMeasure.CVAR,\n    prior_estimator=FactorModel(),\n    portfolio_params=dict(name=\"HRP-CVaR-Factor-Model\"),\n)\nmodel4.fit(X_train, y_train)\n\nmodel4.hierarchical_clustering_estimator_.plot_dendrogram(heatmap=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compare the models, we use an equal weighted benchmark using\nthe :class:`~skfolio.optimization.EqualWeighted` estimator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bench = EqualWeighted()\nbench.fit(X_train)\nbench.weights_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction\nWe predict the models and the benchmark on the test set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population_test = Population([])\nfor model in [model1, model2, model3, model4, bench]:\n    population_test.append(model.predict(X_test))\n\npopulation_test.plot_cumulative_returns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Composition\nFrom the below composition, we notice that all models are relatively close to each\nothers as explain earlier:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population_test.plot_composition()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\nFinally, let's print the summary statistics:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "summary = population_test.summary()\nsummary.loc[\"Annualized Sharpe Ratio\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "summary"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}