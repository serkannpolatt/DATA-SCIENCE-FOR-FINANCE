{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Uncertainty Set\n\nThis tutorial shows how to incorporate expected returns uncertainty sets into the\n:class:`~skfolio.optimization.MeanRisk` optimization.\n\nBy using the `Mu Uncertainty set estimator <uncertainty_set_estimator>`,\nthe assets expected returns are modelled with an ellipsoidal uncertainty set.\nThis approach, known as worst-case optimization, falls under the umbrella of robust\noptimization. It reduces the instability that arises from the estimation errors of the\nexpected returns.\n\nThe worst case portfolio expect return is:\n\n    .. math:: w^T\\hat{\\mu} - \\kappa_{\\mu}\\lVert S_{\\mu}^\\frac{1}{2}w\\rVert_{2}\n\nwith $\\kappa$ the size of the ellipsoid (confidence region) and $S$ its\nshape.\n\nIn this example, we will use a Mean-CVaR model with an\n:class:`~skfolio.uncertainty_set.EmpiricalMuUncertaintySet` estimator.\n\nNote that other uncertainty set can be used, for example:\n:class:`~skfolio.uncertainty_set.BootstrapMuUncertaintySet`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\nWe load the FTSE 100 `dataset <datasets>` composed of the daily prices of 64\nassets from the FTSE 100 Index composition starting from 2000-01-04 up to 2023-05-31:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport plotly.graph_objects as go\nfrom plotly.io import show\nfrom scipy.stats import uniform\nfrom sklearn import clone\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n\nfrom skfolio import PerfMeasure, Population, RatioMeasure, RiskMeasure\nfrom skfolio.datasets import load_ftse100_dataset\nfrom skfolio.metrics import make_scorer\nfrom skfolio.model_selection import WalkForward, cross_val_predict\nfrom skfolio.optimization import MeanRisk, ObjectiveFunction\nfrom skfolio.preprocessing import prices_to_returns\nfrom skfolio.uncertainty_set import EmpiricalMuUncertaintySet\n\nprices = load_ftse100_dataset()\n\nX = prices_to_returns(prices)\nX_train, X_test = train_test_split(X, test_size=0.33, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Efficient Frontier\nFirst, we create a Mean-CVaR model to estimate the efficient frontier without\nuncertainty set. We constrain the CVaR at 95% to be below 2% (representing the\naverage loss of the worst 5% daily returns over the period):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = MeanRisk(\n    risk_measure=RiskMeasure.CVAR,\n    min_weights=-1,\n    max_cvar=0.02,\n    efficient_frontier_size=20,\n    portfolio_params=dict(name=\"Mean-CVaR\", tag=\"No Uncertainty Set\"),\n)\nmodel.fit(X_train)\nmodel.weights_.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we create a robust (worst case) Mean-CVaR model with an uncertainty set on the\nexpected returns:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_uncertainty = MeanRisk(\n    risk_measure=RiskMeasure.CVAR,\n    min_weights=-1,\n    max_cvar=0.02,\n    efficient_frontier_size=20,\n    mu_uncertainty_set_estimator=EmpiricalMuUncertaintySet(confidence_level=0.60),\n    portfolio_params=dict(name=\"Mean-CVaR\", tag=\"Mu Uncertainty Set - 60%\"),\n)\nmodel_uncertainty.fit(X_train)\nmodel_uncertainty.weights_.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot both efficient frontiers on the training set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population_train = model.predict(X_train) + model_uncertainty.predict(X_train)\n\npopulation_train.plot_measures(\n    x=RiskMeasure.CVAR,\n    y=PerfMeasure.ANNUALIZED_MEAN,\n    color_scale=RatioMeasure.ANNUALIZED_SHARPE_RATIO,\n    hover_measures=[RiskMeasure.MAX_DRAWDOWN, RatioMeasure.ANNUALIZED_SORTINO_RATIO],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyper-Parameter Tuning\nIn this section, we consider a 3 months rolling (60 business days) long-short\nallocation fitted on the preceding year of data (252 business days) that maximizes the\nportfolio return under a CVaR constraint.\nWe will use `GridSearchCV` to select the below model parameters on the training set\nusing walk forward analysis with a Mean/CVaR ratio scoring.\n\nThe model parameters to tune are:\n\n  * `max_cvar`: CVaR target (upper constraint)\n  * `cvar_beta`: CVaR confidence level\n  * `confidence_level`: Mu uncertainty set confidence level of the :class:`~skfolio.uncertainty_set.EmpiricalMuUncertaintySet`\n\nFor embedded parameters in the `GridSearchCV`, you need to use a double underscore:\n`mu_uncertainty_set_estimator__confidence_level`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_no_uncertainty = MeanRisk(\n    risk_measure=RiskMeasure.CVAR,\n    objective_function=ObjectiveFunction.MAXIMIZE_RETURN,\n    max_cvar=0.02,\n    cvar_beta=0.9,\n    min_weights=-1,\n)\n\nmodel_uncertainty = clone(model_no_uncertainty)\nmodel_uncertainty.set_params(mu_uncertainty_set_estimator=EmpiricalMuUncertaintySet())\n\ncv = WalkForward(train_size=252, test_size=60)\n\ngrid_search = GridSearchCV(\n    estimator=model_uncertainty,\n    cv=cv,\n    n_jobs=-1,\n    param_grid={\n        \"mu_uncertainty_set_estimator__confidence_level\": [0.80, 0.90],\n        \"max_cvar\": [0.03, 0.04, 0.05],\n        \"cvar_beta\": [0.8, 0.9, 0.95],\n    },\n    scoring=make_scorer(RatioMeasure.CVAR_RATIO),\n)\ngrid_search.fit(X_train)\nbest_model = grid_search.best_estimator_\nprint(best_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The optimal parameters among the above 2x3x3 grid are the `max_cvar=3%`,\n`cvar_beta=90%` and :class:`~skfolio.uncertainty_set.EmpiricalMuUncertaintySet`\n`confidence_level=80%`. These parameters are the ones that achieved the highest mean\nout-of-sample Mean/CVaR ratio.\n\nFor continuous parameters, such as `confidence_level`, a better approach is to use\n`RandomizedSearchCV` and specify a continuous distribution to take full advantage of\nthe randomization. We specify a continuous random variable that is uniformly\ndistributed between 0 and 1:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "randomized_search = RandomizedSearchCV(\n    estimator=model_uncertainty,\n    cv=cv,\n    n_jobs=-1,\n    param_distributions={\n        \"mu_uncertainty_set_estimator__confidence_level\": uniform(loc=0, scale=1),\n    },\n    n_iter=50,\n    scoring=make_scorer(RatioMeasure.CVAR_RATIO),\n)\nrandomized_search.fit(X_train)\nbest_model_rs = randomized_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The selected confidence level is 58%.\n\nLet's plot the average out-of-sample score (CVaR ratio) as a function of the\nuncertainty set confidence level:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv_results = randomized_search.cv_results_\nx = np.asarray(\n    cv_results[\"param_mu_uncertainty_set_estimator__confidence_level\"]\n).astype(float)\nsort_idx = np.argsort(x)\ny_test_mean = cv_results[\"mean_test_score\"][sort_idx]\nx = x[sort_idx]\n\nfig = go.Figure([\n    go.Scatter(\n        x=x,\n        y=y_test_mean,\n        name=\"Test\",\n        mode=\"lines\",\n        line=dict(color=\"rgb(255,165,0)\"),\n    ),\n])\nfig.add_vline(\n    x=randomized_search.best_params_[\"mu_uncertainty_set_estimator__confidence_level\"],\n    line_width=2,\n    line_dash=\"dash\",\n    line_color=\"green\",\n)\nfig.update_layout(\n    title=\"Test score\",\n    xaxis_title=\"Uncertainty Set Confidence Level\",\n    yaxis_title=\"CVaR Ratio\",\n)\nfig.update_yaxes(tickformat=\".3f\")\nfig.update_xaxes(tickformat=\".0%\")\nshow(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|\n\nNow, we analyze all three models on the test set.\nBy using `cross_val_predict` with `WalkForward`, we are able to compute efficiently\nthe `MultiPeriodPortfolio` composed of 60 days rolling portfolios fitted on the\npreceding 252 days:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_no_uncertainty = cross_val_predict(model_no_uncertainty, X_test, cv=cv)\npred_no_uncertainty.name = \"No Uncertainty set\"\n\npred_uncertainty = cross_val_predict(best_model, X_test, cv=cv, n_jobs=-1)\npred_uncertainty.name = \"Uncertainty set - Grid Search\"\n\npred_uncertainty_rs = cross_val_predict(best_model_rs, X_test, cv=cv, n_jobs=-1)\npred_uncertainty_rs.name = \"Uncertainty set - Randomized Search\"\n\npopulation = Population([pred_no_uncertainty, pred_uncertainty, pred_uncertainty_rs])\npopulation.plot_cumulative_returns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the plot and the below summary, we can see that the model without uncertainty set\nis overfitted and perform poorly on the test set. Its CVaR at 95% is 10% and its\nMean/CVaR ratio is 0.006 which is the lowest of all models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's plot the composition of the regularized multi-period portfolio:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_uncertainty.plot_composition()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}